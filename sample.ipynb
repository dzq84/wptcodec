{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import math\n",
    "import torch\n",
    "import torchaudio\n",
    "from tqdm import tqdm\n",
    "from model.codec import CODEC\n",
    "from utils.tools import batch_wdt\n",
    "\n",
    "def load_model(checkpoint_path, device='cuda'):\n",
    "    \"\"\"\n",
    "    Load the trained CODEC model from checkpoint.\n",
    "    \"\"\"\n",
    "    model = CODEC.load_from_checkpoint(checkpoint_path,map_location='cuda:0',sample_rate=16000)\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "def process_audio_in_chunks(file_path, sample_rate, model, chunk_size, device='cuda'):\n",
    "    \"\"\"\n",
    "    Process audio file in chunks to avoid memory issues.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the input audio file.\n",
    "        sample_rate (int): Target sample rate for the model.\n",
    "        model (CODEC): Trained CODEC model.\n",
    "        chunk_size (int): Chunk size in samples.\n",
    "        device (str): Device to run the model ('cuda' or 'cpu').\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Original audio tensor.\n",
    "        torch.Tensor: Reconstructed audio tensor.\n",
    "        torch.Tensor: Quantized codes.\n",
    "    \"\"\"\n",
    "    # Load and preprocess the audio\n",
    "    audio, sr = torchaudio.load(file_path)\n",
    "    if sr != sample_rate:\n",
    "        resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=sample_rate)\n",
    "        audio = resampler(audio)\n",
    "\n",
    "    audio = model.preprocess(audio, sample_rate).to(device)\n",
    "\n",
    "    # Initialize outputs\n",
    "    original_chunks = []\n",
    "    reconstructed_chunks = []\n",
    "    codes_list = []\n",
    "\n",
    "    # Process audio in chunks\n",
    "    for start in range(0, audio.shape[-1], chunk_size):\n",
    "        end = min(start + chunk_size, audio.shape[-1])\n",
    "        chunk = audio[0:1, start:end].unsqueeze(dim=0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Encode the chunk           \n",
    "\n",
    "            audio_data = chunk[:,0:1,:]\n",
    "            z = model.encoder(audio_data)\n",
    "            z_q, codes, latents, commitment_loss, codebook_loss = model.quantizer(z)\n",
    "            # Decode the chunk\n",
    "            reconstructed_chunk = model.decoder(z_q)\n",
    "            # Append codes\n",
    "            codes_list.append(codes)\n",
    "\n",
    "        original_chunks.append(chunk.cpu())\n",
    "        reconstructed_chunks.append(reconstructed_chunk.cpu())\n",
    "\n",
    "    # Concatenate all chunks\n",
    "    original_audio = torch.cat(original_chunks, dim=-1)\n",
    "    reconstructed_audio = torch.cat(reconstructed_chunks, dim=-1)\n",
    "    codes = torch.cat(codes_list, dim=2)  # Concatenate along the time dimension\n",
    "\n",
    "    return original_audio, reconstructed_audio, codes\n",
    "\n",
    "def reconstruct_from_codes(codes, model, device='cuda'):\n",
    "    \"\"\"\n",
    "    Reconstruct audio from quantized codes using RVQ's `from_codes`.\n",
    "    \n",
    "    Args:\n",
    "        codes (torch.Tensor): Quantized codes (B x N x T).\n",
    "        model (CODEC): Trained CODEC model.\n",
    "        device (str): Device to run the model ('cuda' or 'cpu').\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Reconstructed continuous representation z_q.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        z_q, _, _ = model.quantizer.from_codes(codes.to(device))\n",
    "        reconstructed_audio = model.decoder(z_q)\n",
    "    return reconstructed_audio.cpu()\n",
    "\n",
    "def save_audio(audio_tensor, sample_rate, output_path):\n",
    "    \"\"\"\n",
    "    Save audio tensor to file.\n",
    "    \"\"\"\n",
    "    torchaudio.save(output_path, audio_tensor, sample_rate)\n",
    "\n",
    "def process_folder(input_folder, output_original_folder, output_reconstructed_folder, model, sample_rate, chunk_size, device='cuda'):\n",
    "    \"\"\"\n",
    "    Process all .wav files in a folder.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_original_folder):\n",
    "        os.makedirs(output_original_folder)\n",
    "    if not os.path.exists(output_reconstructed_folder):\n",
    "        os.makedirs(output_reconstructed_folder)\n",
    "\n",
    "    # Collect all .wav files\n",
    "    all_files = [\n",
    "        os.path.join(root, file)\n",
    "        for root, _, files in os.walk(input_folder)\n",
    "        for file in files if file.endswith(\".flac\")\n",
    "    ]\n",
    "\n",
    "    # Process with progress bar\n",
    "    for input_file_path in tqdm(all_files, desc=\"Processing files\"):\n",
    "        file_name = os.path.splitext(os.path.basename(input_file_path))[0]\n",
    "\n",
    "        # Process the audio file\n",
    "        original_audio, reconstructed_audio, codes = process_audio_in_chunks(\n",
    "            input_file_path, sample_rate, model, chunk_size, device=device\n",
    "        )\n",
    "\n",
    "        # Ensure both audio have the same length\n",
    "        min_length = min(original_audio.shape[-1], reconstructed_audio.shape[-1])\n",
    "        original_audio = original_audio[..., :min_length]\n",
    "        reconstructed_audio = reconstructed_audio[..., :min_length]\n",
    "\n",
    "        # Save the audio files\n",
    "        output_original_path = os.path.join(output_original_folder, f\"{file_name}_original.wav\")\n",
    "        output_reconstructed_path = os.path.join(output_reconstructed_folder, f\"{file_name}_reconstructed.wav\")\n",
    "        save_audio(original_audio[0], sample_rate, output_original_path)\n",
    "        save_audio(reconstructed_audio[0], sample_rate, output_reconstructed_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Paths and parameters\n",
    "    checkpoint_path = \"/workspace/wptcodec/daccodec-speech/checkpoints/epoch-epoch=61-loss-train_loss=0.00.ckpt\"  # Replace with the path to your trained model checkpoint\n",
    "    input_folder = \"/datasets/LibriSpeech/test-clean/\"  # Replace with the folder containing input .wav files\n",
    "    output_original_folder = \"/workspace/wptcodec/daccodec-speech/original\"  # Folder to save original audio\n",
    "    output_reconstructed_folder = \"/workspace/wptcodec/daccodec-speech/reconstructed\"  # Folder to save reconstructed audio\n",
    "    sample_rate = 16000  # Model's expected sample rate\n",
    "    chunk_size = 16384*1  # Process ~5 seconds at a time\n",
    "\n",
    "    # Load the model\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = load_model(checkpoint_path, device=device)\n",
    "\n",
    "    # Process all files in the folder\n",
    "    process_folder(\n",
    "        input_folder, output_original_folder, output_reconstructed_folder,\n",
    "        model, sample_rate, chunk_size, device=device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import math\n",
    "import torch\n",
    "import torchaudio\n",
    "from tqdm import tqdm\n",
    "from model.wptcodec import CODEC\n",
    "from utils.tools import batch_wdt\n",
    "\n",
    "def load_model(checkpoint_path, device='cuda'):\n",
    "    \"\"\"\n",
    "    Load the trained CODEC model from checkpoint.\n",
    "    \"\"\"\n",
    "    model = CODEC.load_from_checkpoint(checkpoint_path,map_location='cuda:0',sample_rate=16000)\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "def process_audio_in_chunks(file_path, sample_rate, model, chunk_size, device='cuda'):\n",
    "    \"\"\"\n",
    "    Process audio file in chunks to avoid memory issues.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the input audio file.\n",
    "        sample_rate (int): Target sample rate for the model.\n",
    "        model (CODEC): Trained CODEC model.\n",
    "        chunk_size (int): Chunk size in samples.\n",
    "        device (str): Device to run the model ('cuda' or 'cpu').\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Original audio tensor.\n",
    "        torch.Tensor: Reconstructed audio tensor.\n",
    "        torch.Tensor: Quantized codes.\n",
    "    \"\"\"\n",
    "    # Load and preprocess the audio\n",
    "    audio, sr = torchaudio.load(file_path)\n",
    "    if sr != sample_rate:\n",
    "        resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=sample_rate)\n",
    "        audio = resampler(audio)\n",
    "\n",
    "    audio = model.preprocess(audio, sample_rate).to(device)\n",
    "\n",
    "    # Initialize outputs\n",
    "    original_chunks = []\n",
    "    reconstructed_chunks = []\n",
    "    codes_list = []\n",
    "\n",
    "    # Process audio in chunks\n",
    "    for start in range(0, audio.shape[-1], chunk_size):\n",
    "        end = min(start + chunk_size, audio.shape[-1])\n",
    "        chunk = audio[0:1, start:end].unsqueeze(dim=0)\n",
    "\n",
    "        if chunk.shape[2]<512:\n",
    "            break\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Encode the chunk           \n",
    "\n",
    "            audio_data = chunk[:,0:1,:]\n",
    "            nodes = batch_wdt(audio_data,max_level=4)\n",
    "            nodes_data = model.preprocess(nodes, model.sample_rate)\n",
    "            nodes_data = nodes\n",
    "\n",
    "            z = model.encoder(nodes_data)\n",
    "            z_q, codes, latents, commitment_loss, codebook_loss = model.quantizer(z)\n",
    "            # Decode the chunk\n",
    "            reconstructed_chunk = model.decoder(z_q)\n",
    "            # Append codes\n",
    "            codes_list.append(codes)\n",
    "\n",
    "        original_chunks.append(chunk.cpu())\n",
    "        reconstructed_chunks.append(reconstructed_chunk.cpu())\n",
    "\n",
    "    # Concatenate all chunks\n",
    "    original_audio = torch.cat(original_chunks, dim=-1)\n",
    "    reconstructed_audio = torch.cat(reconstructed_chunks, dim=-1)\n",
    "    codes = torch.cat(codes_list, dim=2)  # Concatenate along the time dimension\n",
    "\n",
    "    return original_audio, reconstructed_audio, codes\n",
    "\n",
    "def reconstruct_from_codes(codes, model, device='cuda'):\n",
    "    \"\"\"\n",
    "    Reconstruct audio from quantized codes using RVQ's `from_codes`.\n",
    "    \n",
    "    Args:\n",
    "        codes (torch.Tensor): Quantized codes (B x N x T).\n",
    "        model (CODEC): Trained CODEC model.\n",
    "        device (str): Device to run the model ('cuda' or 'cpu').\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Reconstructed continuous representation z_q.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        z_q, _, _ = model.quantizer.from_codes(codes.to(device))\n",
    "        reconstructed_audio = model.decoder(z_q)\n",
    "    return reconstructed_audio.cpu()\n",
    "\n",
    "def save_audio(audio_tensor, sample_rate, output_path):\n",
    "    \"\"\"\n",
    "    Save audio tensor to file.\n",
    "    \"\"\"\n",
    "    torchaudio.save(output_path, audio_tensor, sample_rate)\n",
    "\n",
    "def process_folder(input_folder, output_original_folder, output_reconstructed_folder, model, sample_rate, chunk_size, device='cuda'):\n",
    "    \"\"\"\n",
    "    Process all .wav files in a folder.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_original_folder):\n",
    "        os.makedirs(output_original_folder)\n",
    "    if not os.path.exists(output_reconstructed_folder):\n",
    "        os.makedirs(output_reconstructed_folder)\n",
    "\n",
    "    # Collect all .wav files\n",
    "    all_files = [\n",
    "        os.path.join(root, file)\n",
    "        for root, _, files in os.walk(input_folder)\n",
    "        for file in files if file.endswith(\".flac\")\n",
    "    ]\n",
    "\n",
    "    # Process with progress bar\n",
    "    for input_file_path in tqdm(all_files, desc=\"Processing files\"):\n",
    "        file_name = os.path.splitext(os.path.basename(input_file_path))[0]\n",
    "\n",
    "        # Process the audio file\n",
    "        original_audio, reconstructed_audio, codes = process_audio_in_chunks(\n",
    "            input_file_path, sample_rate, model, chunk_size, device=device\n",
    "        )\n",
    "\n",
    "        # Ensure both audio have the same length\n",
    "        min_length = min(original_audio.shape[-1], reconstructed_audio.shape[-1])\n",
    "        original_audio = original_audio[..., :min_length]\n",
    "        reconstructed_audio = reconstructed_audio[..., :min_length]\n",
    "\n",
    "        # Save the audio files\n",
    "        output_original_path = os.path.join(output_original_folder, f\"{file_name}_original.wav\")\n",
    "        output_reconstructed_path = os.path.join(output_reconstructed_folder, f\"{file_name}_reconstructed.wav\")\n",
    "        save_audio(original_audio[0], sample_rate, output_original_path)\n",
    "        save_audio(reconstructed_audio[0], sample_rate, output_reconstructed_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Paths and parameters\n",
    "    checkpoint_path = \"/workspace/wptcodec/wptcodec-speech-4/checkpoints/epoch-epoch=61-loss-train_loss=0.00.ckpt\"  # Replace with the path to your trained model checkpoint\n",
    "    input_folder = \"/datasets/LibriSpeech/test-clean/\"  # Replace with the folder containing input .wav files\n",
    "    output_original_folder = \"/workspace/wptcodec/wptcodec-speech-4/original\"  # Folder to save original audio\n",
    "    output_reconstructed_folder = \"/workspace/wptcodec/wptcodec-speech-4/reconstructed\"  # Folder to save reconstructed audio\n",
    "    sample_rate = 16000  # Model's expected sample rate\n",
    "    chunk_size = 16384*1  # Process ~5 seconds at a time\n",
    "\n",
    "    # Load the model\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = load_model(checkpoint_path, device=device)\n",
    "\n",
    "    # Process all files in the folder\n",
    "    process_folder(\n",
    "        input_folder, output_original_folder, output_reconstructed_folder,\n",
    "        model, sample_rate, chunk_size, device=device\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from nn.loss import mel_spectrogram_loss, multi_scale_stft_loss,sisdr_loss  # Replace with actual import path\n",
    "import torchaudio\n",
    "\n",
    "\n",
    "def compute_metrics(original: torch.Tensor, reconstructed: torch.Tensor, sample_rate: int) -> dict:\n",
    "    \"\"\"\n",
    "    Compute audio metrics (mel loss and STFT loss) between original and reconstructed audio.\n",
    "\n",
    "    Args:\n",
    "        original (torch.Tensor): Original audio tensor (B x T).\n",
    "        reconstructed (torch.Tensor): Reconstructed audio tensor (B x T).\n",
    "        sample_rate (int): Sampling rate of the audio.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing the computed metrics.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"mel_loss\": mel_spectrogram_loss(original, reconstructed, sample_rate=sample_rate).item(),\n",
    "        \"stft_loss\": multi_scale_stft_loss(original, reconstructed).item(),\n",
    "        \"sisdr_loss\":sisdr_loss(original.squeeze(dim=0),reconstructed.squeeze(dim=0))\n",
    "    }\n",
    "\n",
    "\n",
    "def process_audio_files(original_dir: str, reconstructed_dir: str, sample_rate: int) -> dict:\n",
    "    \"\"\"\n",
    "    Compute average metrics for all audio files in the original and reconstructed directories.\n",
    "\n",
    "    Args:\n",
    "        original_dir (str): Path to the directory containing original audio files.\n",
    "        reconstructed_dir (str): Path to the directory containing reconstructed audio files.\n",
    "        sample_rate (int): Sampling rate for the audio files.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing the average metrics.\n",
    "    \"\"\"\n",
    "    # Find all original and reconstructed files\n",
    "    original_files = sorted(list(Path(original_dir).glob(\"*.wav\")))\n",
    "    reconstructed_files = sorted(list(Path(reconstructed_dir).glob(\"*.wav\")))\n",
    "\n",
    "    assert len(original_files) == len(\n",
    "        reconstructed_files\n",
    "    ), \"Mismatch between the number of original and reconstructed files.\"\n",
    "\n",
    "    total_metrics = {\"mel_loss\": 0.0, \"stft_loss\": 0.0,\"sisdr_loss\":0.0}\n",
    "    num_files = len(original_files)\n",
    "\n",
    "    for original_path, reconstructed_path in zip(original_files, reconstructed_files):\n",
    "        print(f\"Processing: {original_path.name}\")\n",
    "        # Load audio files\n",
    "        original_audio, _ = torchaudio.load(original_path)\n",
    "        reconstructed_audio, _ = torchaudio.load(reconstructed_path)\n",
    "\n",
    "        # Compute metrics\n",
    "        metrics = compute_metrics(original_audio.unsqueeze(dim=0), reconstructed_audio.unsqueeze(dim=0), sample_rate=sample_rate)\n",
    "        total_metrics[\"mel_loss\"] += metrics[\"mel_loss\"]\n",
    "        total_metrics[\"stft_loss\"] += metrics[\"stft_loss\"]\n",
    "        total_metrics[\"sisdr_loss\"] += metrics[\"sisdr_loss\"]\n",
    "\n",
    "    # Compute averages\n",
    "    average_metrics = {k: v / num_files for k, v in total_metrics.items()}\n",
    "    return average_metrics\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Specify directories and sample rate\n",
    "    original_dir = \"/workspace/wptcodec/daccodec-speech/original\"  # Replace with the actual path\n",
    "    reconstructed_dir = \"/workspace/wptcodec/daccodec-speech/reconstructed/\"  # Replace with the actual path\n",
    "    sample_rate = 16000  # Replace with your desired sample rate\n",
    "\n",
    "    # Process audio files and compute average metrics\n",
    "    avg_metrics = process_audio_files(original_dir, reconstructed_dir, sample_rate)\n",
    "\n",
    "    # Print the average metrics\n",
    "    print(\"\\nAverage Metrics:\")\n",
    "    for k, v in avg_metrics.items():\n",
    "        print(f\"{k}: {v:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanogpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
